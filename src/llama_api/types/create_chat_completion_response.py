# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.

from typing import List, Union, Optional
from typing_extensions import Literal, TypeAlias

from .._models import BaseModel

__all__ = [
    "CreateChatCompletionResponse",
    "CompletionMessage",
    "CompletionMessageContent",
    "CompletionMessageContentMessageTextContentItem",
    "CompletionMessageContentMessageReasoningContentItem",
    "CompletionMessageToolCall",
    "CompletionMessageToolCallFunction",
    "Metric",
]


class CompletionMessageContentMessageTextContentItem(BaseModel):
    text: str
    """Text content"""

    type: Literal["text"]
    """Discriminator type of the content item. Always "text" """


class CompletionMessageContentMessageReasoningContentItem(BaseModel):
    answer: str
    """The final model response"""

    reasoning: str
    """The CoT reasoning content of the model"""

    type: Literal["reasoning"]
    """Discriminator type of the content item. Always "reasoning" """


CompletionMessageContent: TypeAlias = Union[
    str, CompletionMessageContentMessageTextContentItem, CompletionMessageContentMessageReasoningContentItem
]


class CompletionMessageToolCallFunction(BaseModel):
    arguments: str
    """
    The arguments to call the function with, as generated by the model in JSON
    format. Note that the model does not always generate valid JSON, and may
    hallucinate parameters not defined by your function schema. Validate the
    arguments in your code before calling your function.
    """

    name: str
    """The name of the function to call."""


class CompletionMessageToolCall(BaseModel):
    id: str
    """The ID of the tool call."""

    function: CompletionMessageToolCallFunction
    """The function that the model called."""


class CompletionMessage(BaseModel):
    content: CompletionMessageContent
    """The content of the model's response."""

    role: Literal["assistant"]
    """Must be "assistant" to identify this as the model's response"""

    stop_reason: Literal["stop", "tool_calls", "length"]
    """The reason why we stopped.

    Options are: - "stop": The model reached a natural stopping point. -
    "tool_calls": The model finished generating and invoked a tool call. - "length":
    The model reached the maxinum number of tokens specified in the request.
    """

    tool_calls: Optional[List[CompletionMessageToolCall]] = None
    """The tool calls generated by the model, such as function calls."""


class Metric(BaseModel):
    metric: str

    value: float

    unit: Optional[str] = None


class CreateChatCompletionResponse(BaseModel):
    completion_message: CompletionMessage
    """The complete response message"""

    metrics: Optional[List[Metric]] = None
